# å¯¼å…¥æ“ä½œç³»ç»Ÿç›¸å…³åŠŸèƒ½ï¼Œç”¨äºè·¯å¾„æ“ä½œå’Œæ–‡ä»¶ç®¡ç†
import os
# å¯¼å…¥æ·±æ‹·è´åŠŸèƒ½ï¼Œç”¨äºåˆ›å»ºæ¨¡å‹çš„ç‹¬ç«‹å‰¯æœ¬ï¼ˆEMAæ¨¡å‹ï¼‰
import copy
# å¯¼å…¥NumPyæ•°å€¼è®¡ç®—åº“ï¼Œç”¨äºæ•°ç»„æ“ä½œå’Œéšæœºæ•°ç”Ÿæˆ
import numpy as np
# å¯¼å…¥PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶çš„æ ¸å¿ƒæ¨¡å—
import torch
# å¯¼å…¥PyTorchçš„ç¥ç»ç½‘ç»œæ¨¡å—ï¼ŒåŒ…å«æŸå¤±å‡½æ•°å’Œç½‘ç»œå±‚
import torch.nn as nn
# å¯¼å…¥è¿›åº¦æ¡åº“ï¼Œç”¨äºæ˜¾ç¤ºè®­ç»ƒè¿›åº¦
from tqdm import tqdm
# å¯¼å…¥PyTorchçš„ä¼˜åŒ–å™¨æ¨¡å—
from torch import optim
# å¯¼å…¥è‡ªå®šä¹‰çš„å·¥å…·å‡½æ•°ï¼ˆæ•°æ®åŠ è½½ã€å›¾åƒä¿å­˜ç­‰ï¼‰
from utils import *
# å¯¼å…¥è‡ªå®šä¹‰çš„ç½‘ç»œæ¨¡å—ï¼ˆæ¡ä»¶UNetå’ŒEMAï¼‰
from modules import UNet_conditional, EMA
# å¯¼å…¥æ—¥å¿—è®°å½•æ¨¡å—ï¼Œç”¨äºè¾“å‡ºè®­ç»ƒä¿¡æ¯
import logging
# å¯¼å…¥TensorBoardå†™å…¥å™¨ï¼Œç”¨äºè®°å½•è®­ç»ƒæŒ‡æ ‡å’Œå¯è§†åŒ–
from torch.utils.tensorboard import SummaryWriter
# å¯¼å…¥MPSè®­ç»ƒç›‘æ§å™¨å’Œæ—©åœç›‘æ§å™¨
from mps_training_monitor import get_monitor
from early_stopping_monitor import EarlyStoppingMonitor

# é…ç½®æ—¥å¿—æ ¼å¼ï¼šæ˜¾ç¤ºæ—¶é—´æˆ³ã€æ—¥å¿—çº§åˆ«å’Œæ¶ˆæ¯å†…å®¹
# level=logging.INFOè¡¨ç¤ºè®°å½•INFOçº§åˆ«åŠä»¥ä¸Šçš„æ—¥å¿—
# datefmtè®¾ç½®æ—¶é—´æ ¼å¼ä¸ºå°æ—¶:åˆ†é’Ÿ:ç§’
logging.basicConfig(format="%(asctime)s - %(levelname)s: %(message)s", level=logging.INFO, datefmt="%I:%M:%S")


class Diffusion:
    """
    æ‰©æ•£æ¨¡å‹çš„æ ¸å¿ƒç±»ï¼Œå®ç°å‰å‘åŠ å™ªè¿‡ç¨‹å’Œåå‘å»å™ªè¿‡ç¨‹
    åŒ…å«å™ªå£°è°ƒåº¦ã€æ—¶é—´æ­¥é‡‡æ ·ã€å›¾åƒåŠ å™ªå’Œé‡‡æ ·ç”Ÿæˆç­‰åŠŸèƒ½
    """
    def __init__(self, noise_steps=1000, beta_start=1e-4, beta_end=0.02, img_size=256, device="cuda"):
        """
        åˆå§‹åŒ–æ‰©æ•£æ¨¡å‹å‚æ•°
        å‚æ•°:
            noise_steps: æ‰©æ•£è¿‡ç¨‹çš„æ€»æ—¶é—´æ­¥æ•°ï¼Œé»˜è®¤1000æ­¥
            beta_start: å™ªå£°è°ƒåº¦çš„èµ·å§‹å€¼ï¼Œæ§åˆ¶åˆå§‹å™ªå£°å¼ºåº¦
            beta_end: å™ªå£°è°ƒåº¦çš„ç»“æŸå€¼ï¼Œæ§åˆ¶æœ€ç»ˆå™ªå£°å¼ºåº¦
            img_size: å›¾åƒå°ºå¯¸ï¼ˆæ­£æ–¹å½¢å›¾åƒçš„è¾¹é•¿ï¼‰
            device: è®¡ç®—è®¾å¤‡ï¼ˆ"cuda"æˆ–"cpu"ï¼‰
        """
        # å­˜å‚¨æ‰©æ•£è¿‡ç¨‹çš„æ€»æ—¶é—´æ­¥æ•°
        self.noise_steps = noise_steps
        # å­˜å‚¨å™ªå£°è°ƒåº¦çš„èµ·å§‹å€¼ï¼ˆè¾ƒå°ï¼ŒåˆæœŸåŠ å™ªè¾ƒå°‘ï¼‰
        self.beta_start = beta_start
        # å­˜å‚¨å™ªå£°è°ƒåº¦çš„ç»“æŸå€¼ï¼ˆè¾ƒå¤§ï¼ŒåæœŸåŠ å™ªè¾ƒå¤šï¼‰
        self.beta_end = beta_end
        # å­˜å‚¨å›¾åƒå°ºå¯¸
        self.img_size = img_size
        # å­˜å‚¨è®¡ç®—è®¾å¤‡
        self.device = device

        # ç”Ÿæˆå™ªå£°è°ƒåº¦åºåˆ—å¹¶ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
        self.beta = self.prepare_noise_schedule().to(device)
        # è®¡ç®—alphaåºåˆ—ï¼šalpha_t = 1 - beta_tï¼Œè¡¨ç¤ºä¿ç•™åŸå›¾åƒçš„æ¯”ä¾‹
        self.alpha = 1. - self.beta
        # è®¡ç®—ç´¯ç§¯ä¹˜ç§¯alpha_hatï¼šç”¨äºç›´æ¥ä»x_0è®¡ç®—x_tï¼Œé¿å…é€æ­¥è®¡ç®—
        self.alpha_hat = torch.cumprod(self.alpha, dim=0)
        # é¢„è®¡ç®—å™ªå£°ç³»æ•°ï¼Œé¿å…è®­ç»ƒå¾ªç¯é‡Œé‡å¤åˆ†è§£è°ƒåº¦è¡¨ï¼Œæé«˜è®¡ç®—æ•ˆç‡

    def prepare_noise_schedule(self):
        """
        ç”Ÿæˆæ¯ä¸ªæ—¶é—´æ­¥çš„å™ªå£°å¼ºåº¦betaå€¼
        ä½¿ç”¨çº¿æ€§è°ƒåº¦ï¼šä»beta_startçº¿æ€§å¢é•¿åˆ°beta_end
        è¿”å›: å½¢çŠ¶ä¸º(noise_steps,)çš„tensorï¼ŒåŒ…å«æ¯ä¸ªæ—¶é—´æ­¥çš„betaå€¼
        """
        # åˆ›å»ºä»beta_startåˆ°beta_endçš„çº¿æ€§åºåˆ—
        # éšç€æ—¶é—´æ­¥å¢åŠ ï¼Œbetaå€¼å¢å¤§ï¼Œæ„å‘³ç€åŠ å…¥æ›´å¤šå™ªå£°
        return torch.linspace(self.beta_start, self.beta_end, self.noise_steps)

    def sample_timesteps(self, n):
        """
        ä¸ºæ¯å¼ å›¾åƒéšæœºé‡‡æ ·æ—¶é—´æ­¥
        åœ¨è®­ç»ƒæ—¶ï¼Œæ¯ä¸ªæ ·æœ¬éœ€è¦éšæœºé€‰æ‹©ä¸€ä¸ªæ—¶é—´æ­¥è¿›è¡ŒåŠ å™ª
        å‚æ•°:
            n: æ‰¹æ¬¡å¤§å°ï¼ˆbatch_sizeï¼‰
        è¿”å›:
            t: æ—¶é—´æ­¥tensorï¼Œå½¢çŠ¶ä¸º(n,)ï¼Œå€¼åœ¨[1, noise_steps)èŒƒå›´å†…
        """
        # ä¸ºæ¯ä¸ªæ ·æœ¬éšæœºé€‰æ‹©ä¸€ä¸ªæ—¶é—´æ­¥
        # low=1è¡¨ç¤ºä»æ—¶é—´æ­¥1å¼€å§‹ï¼ˆé¿å…t=0çš„è¾¹ç•Œæƒ…å†µï¼‰
        # high=self.noise_stepsè¡¨ç¤ºæœ€å¤§æ—¶é—´æ­¥ï¼ˆä¸åŒ…å«ï¼‰
        return torch.randint(low=1, high=self.noise_steps, size=(n, ))

    def noise_images(self, x, t):
        """
        å‰å‘åŠ å™ªè¿‡ç¨‹ï¼šå°†å¹²å‡€å›¾åƒx_0ç›´æ¥åŠ å™ªåˆ°æ—¶é—´æ­¥tå¾—åˆ°x_t
        ä½¿ç”¨é‡å‚æ•°åŒ–æŠ€å·§ï¼Œå¯ä»¥ç›´æ¥ä»x_0è®¡ç®—ä»»æ„æ—¶é—´æ­¥çš„x_t
        å‚æ•°:
            x: è¾“å…¥å›¾åƒï¼Œå½¢çŠ¶ä¸º(batch_size, channels, img_size, img_size)
            t: æ—¶é—´æ­¥ï¼Œå½¢çŠ¶ä¸º(batch_size,)
        è¿”å›:
            åŠ å™ªåçš„å›¾åƒx_tå’Œå¯¹åº”çš„å™ªå£°epsilon
            å…¬å¼: x_t = sqrt(alpha_hat[t]) * x_0 + sqrt(1 - alpha_hat[t]) * epsilon
        """
        # è·å–æ—¶é—´æ­¥tå¯¹åº”çš„alpha_hatå€¼çš„å¹³æ–¹æ ¹
        # [:, None, None, None]ç”¨äºå¹¿æ’­åˆ°å›¾åƒçš„æ‰€æœ‰ç»´åº¦
        sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:, None, None, None]
        # è·å–(1 - alpha_hat[t])çš„å¹³æ–¹æ ¹ï¼Œæ§åˆ¶å™ªå£°çš„å¼ºåº¦
        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alpha_hat[t])[:, None, None, None]
        # ç”Ÿæˆä¸è¾“å…¥å›¾åƒç›¸åŒå½¢çŠ¶çš„éšæœºå™ªå£°
        Æ = torch.randn_like(x)
        # æŒ‰æ‰©æ•£æ¨¡å‹çš„é‡å‚æ•°åŒ–å…¬å¼æ··åˆçœŸå®å›¾åƒä¸éšæœºå™ªå£°
        # è¿”å›åŠ å™ªåçš„å›¾åƒå’ŒçœŸå®å™ªå£°ï¼ˆç”¨äºè®­ç»ƒæ—¶çš„æŸå¤±è®¡ç®—ï¼‰
        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * Æ, Æ

    def sample(self, model, n, labels, cfg_scale=3):
        """
        åå‘å»å™ªè¿‡ç¨‹ï¼šä»çº¯å™ªå£°x_Té€æ­¥å»å™ªç”Ÿæˆå¹²å‡€å›¾åƒx_0
        å®ç°Classifier-Free Guidanceä»¥æé«˜æ¡ä»¶ç”Ÿæˆçš„è´¨é‡
        å‚æ•°:
            model: è®­ç»ƒå¥½çš„UNetæ¨¡å‹ï¼Œç”¨äºé¢„æµ‹å™ªå£°
            n: è¦ç”Ÿæˆçš„å›¾åƒæ•°é‡ï¼ˆæ‰¹æ¬¡å¤§å°ï¼‰
            labels: æ¡ä»¶æ ‡ç­¾ï¼Œå½¢çŠ¶ä¸º(n,)ï¼Œå€¼åœ¨[0, num_classes-1]èŒƒå›´å†…
            cfg_scale: Classifier-Free Guidanceçš„ç¼©æ”¾å› å­
                      0.0è¡¨ç¤ºæ— æ¡ä»¶ç”Ÿæˆï¼Œ>1.0è¡¨ç¤ºå¢å¼ºæ¡ä»¶å¼•å¯¼
        è¿”å›:
            ç”Ÿæˆçš„å›¾åƒï¼Œå½¢çŠ¶ä¸º(n, 3, img_size, img_size)ï¼Œåƒç´ å€¼åœ¨[0, 255]
            å»å™ªå…¬å¼: x_{t-1} = 1/sqrt(alpha[t]) * (x_t - (1-alpha[t])/sqrt(1-alpha_hat[t]) * predicted_noise) + sqrt(beta[t]) * noise
        """
        # è®°å½•å¼€å§‹ç”Ÿæˆå›¾åƒçš„æ—¥å¿—ä¿¡æ¯
        logging.info(f"Sampling {n} new images....")
        # å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼Œç¦ç”¨dropoutå’Œbatch normalizationçš„è®­ç»ƒè¡Œä¸º
        model.eval()
        # ä½¿ç”¨torch.no_grad()ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ŒèŠ‚çœå†…å­˜å¹¶åŠ é€Ÿæ¨ç†
        with torch.no_grad():
            # åˆå§‹åŒ–ä¸ºçº¯éšæœºå™ªå£°ï¼Œè¿™æ˜¯æ‰©æ•£è¿‡ç¨‹çš„èµ·ç‚¹x_T
            # å½¢çŠ¶ä¸º(n, 3, img_size, img_size)ï¼Œ3è¡¨ç¤ºRGBä¸‰ä¸ªé€šé“
            x = torch.randn((n, 3, self.img_size, self.img_size)).to(self.device)
            # ä»æœ€å¤§æ—¶é—´æ­¥å¼€å§‹ï¼Œé€æ­¥å‘t=0å»å™ª
            # reversed(range(1, self.noise_steps))ç”Ÿæˆ[T-1, T-2, ..., 1]çš„åºåˆ—
            for i in tqdm(reversed(range(1, self.noise_steps)), position=0):
                # ä¸ºå½“å‰æ‰¹æ¬¡çš„æ‰€æœ‰æ ·æœ¬åˆ›å»ºç›¸åŒçš„æ—¶é—´æ­¥tensor
                t = (torch.ones(n) * i).long().to(self.device)
                # ä½¿ç”¨æ¨¡å‹é¢„æµ‹å½“å‰æ—¶é—´æ­¥çš„å™ªå£°ï¼ˆæ¡ä»¶ç”Ÿæˆï¼‰
                predicted_noise = model(x, t, labels)
                # å®ç°Classifier-Free Guidanceï¼šç»“åˆæ¡ä»¶å’Œæ— æ¡ä»¶é¢„æµ‹
                if cfg_scale > 0:
                    # è·å–æ— æ¡ä»¶é¢„æµ‹ï¼ˆlabels=Noneï¼‰
                    uncond_predicted_noise = model(x, t, None)
                    # ä½¿ç”¨çº¿æ€§æ’å€¼ç»“åˆä¸¤ç§é¢„æµ‹ï¼Œcfg_scaleæ§åˆ¶æ¡ä»¶å¼•å¯¼çš„å¼ºåº¦
                    # cfg_scale > 1æ—¶ä¼šæ”¾å¤§æ¡ä»¶å’Œæ— æ¡ä»¶é¢„æµ‹çš„å·®å¼‚ï¼Œå¢å¼ºæ¡ä»¶æ§åˆ¶
                    predicted_noise = torch.lerp(uncond_predicted_noise, predicted_noise, cfg_scale)
                # è·å–å½“å‰æ—¶é—´æ­¥çš„æ‰©æ•£å‚æ•°ï¼Œå¹¶æ‰©å±•ç»´åº¦ä»¥åŒ¹é…å›¾åƒå½¢çŠ¶
                alpha = self.alpha[t][:, None, None, None]
                alpha_hat = self.alpha_hat[t][:, None, None, None]
                beta = self.beta[t][:, None, None, None]
                # åœ¨éæœ€åä¸€æ­¥æ—¶æ·»åŠ éšæœºå™ªå£°ï¼Œä¿æŒæ‰©æ•£è¿‡ç¨‹çš„éšæœºæ€§
                if i > 1:
                    noise = torch.randn_like(x)
                else:
                    # æœ€åä¸€æ­¥(t=1->t=0)ä¸æ·»åŠ å™ªå£°ï¼Œç¡®ä¿æœ€ç»ˆç»“æœç¡®å®š
                    noise = torch.zeros_like(x)
                # æ‰§è¡Œåå‘æ‰©æ•£çš„æ ¸å¿ƒå…¬å¼ï¼Œä»x_tè®¡ç®—x_{t-1}
                # è¿™ä¸ªå…¬å¼æ¥æºäºæ‰©æ•£æ¨¡å‹çš„æ•°å­¦æ¨å¯¼ï¼Œç”¨äºé€æ­¥å»é™¤å™ªå£°
                x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise
        # æ¢å¤æ¨¡å‹çš„è®­ç»ƒæ¨¡å¼
        model.train()
        # å°†ç”Ÿæˆçš„å›¾åƒä»[-1, 1]èŒƒå›´æ˜ å°„åˆ°[0, 1]
        x = (x.clamp(-1, 1) + 1) / 2
        # å°†åƒç´ å€¼ä»[0, 1]ç¼©æ”¾åˆ°[0, 255]å¹¶è½¬æ¢ä¸ºuint8ç±»å‹
        x = (x * 255).type(torch.uint8)
        return x


def train(args):
    """
    æ‰©æ•£æ¨¡å‹çš„è®­ç»ƒä¸»å‡½æ•°
    è®­ç»ƒè¿‡ç¨‹ï¼šæ¯ä¸ªepochä¸­ï¼Œå¯¹æ¯ä¸ªbatchéšæœºé€‰æ‹©æ—¶é—´æ­¥ï¼Œæ¯”è¾ƒé¢„æµ‹å™ªå£°ä¸çœŸå®å™ªå£°
    å®ç°Classifier-Free Guidanceè®­ç»ƒç­–ç•¥ï¼Œæé«˜æ¡ä»¶ç”Ÿæˆè´¨é‡
    ç°åœ¨é›†æˆäº†MPSç›‘æ§åŠŸèƒ½ï¼Œæä¾›è¯¦ç»†çš„è®­ç»ƒè¿›åº¦å’Œæ€§èƒ½ä¿¡æ¯
    å‚æ•°:
        args: åŒ…å«è®­ç»ƒé…ç½®çš„å‚æ•°å¯¹è±¡
    """
    # ğŸ” åˆå§‹åŒ–è®­ç»ƒç›‘æ§å™¨
    monitor = get_monitor(args.device)
    monitor.start_monitoring()
    monitor.print_system_info()
    
    # ğŸ›¡ï¸ åˆå§‹åŒ–æ—©åœç›‘æ§å™¨
    early_stopping = EarlyStoppingMonitor(
        patience=25,              # 25ä¸ªepochæ— æ”¹è¿›å°±æé†’
        min_delta=1e-6,          # æœ€å°æ”¹è¿›é˜ˆå€¼
        smoothing_window=10,     # 10ä¸ªepochçš„å¹³æ»‘çª—å£
        convergence_threshold=1e-5,  # æ”¶æ•›é˜ˆå€¼
        auto_stop=False,         # æ‰‹åŠ¨ç¡®è®¤åœæ­¢ï¼ˆæ›´å®‰å…¨ï¼‰
        save_plots=True          # ä¿å­˜åˆ†æå›¾è¡¨
    )

    # åˆ›å»ºè®­ç»ƒæ‰€éœ€çš„ç›®å½•ç»“æ„ï¼ˆmodelsã€resultsç­‰ï¼‰
    setup_logging(args.run_name)
    # è·å–è®¡ç®—è®¾å¤‡ï¼ˆGPUæˆ–CPUï¼‰
    device = args.device
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼Œç”¨äºæ‰¹é‡åŠ è½½å’Œé¢„å¤„ç†è®­ç»ƒæ•°æ®
    dataloader = get_data(args)
    # åˆå§‹åŒ–æ¡ä»¶UNetæ¨¡å‹å¹¶ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
    model = UNet_conditional(num_classes=args.num_classes, device=device, img_size=args.image_size).to(device)
    # ä½¿ç”¨AdamWä¼˜åŒ–å™¨ï¼Œå®ƒåœ¨æ‰©æ•£æ¨¡å‹è®­ç»ƒä¸­è¡¨ç°è‰¯å¥½
    optimizer = optim.AdamW(model.parameters(), lr=args.lr)
    # å®šä¹‰å‡æ–¹è¯¯å·®æŸå¤±å‡½æ•°ï¼Œç”¨äºæ¯”è¾ƒé¢„æµ‹å™ªå£°å’ŒçœŸå®å™ªå£°
    mse = nn.MSELoss()
    # åˆå§‹åŒ–æ‰©æ•£è¿‡ç¨‹ç®¡ç†å™¨
    diffusion = Diffusion(img_size=args.image_size, device=device)
    # åˆ›å»ºTensorBoardæ—¥å¿—å†™å…¥å™¨ï¼Œç”¨äºè®°å½•è®­ç»ƒæŒ‡æ ‡
    logger = SummaryWriter(os.path.join("runs", args.run_name))
    # è·å–æ•°æ®åŠ è½½å™¨çš„é•¿åº¦ï¼Œç”¨äºè®¡ç®—å…¨å±€æ­¥æ•°
    l = len(dataloader)
    # åˆå§‹åŒ–æŒ‡æ•°ç§»åŠ¨å¹³å‡(EMA)ï¼Œè¡°å‡ç‡ä¸º0.995
    # EMAæœ‰åŠ©äºç¨³å®šè®­ç»ƒå¹¶æé«˜ç”Ÿæˆè´¨é‡
    ema = EMA(0.995)
    # åˆ›å»ºEMAæ¨¡å‹ï¼šæ·±æ‹·è´ä¸»æ¨¡å‹å¹¶è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼Œç¦ç”¨æ¢¯åº¦è®¡ç®—
    ema_model = copy.deepcopy(model).eval().requires_grad_(False)

    # å¼€å§‹è®­ç»ƒå¾ªç¯ï¼Œéå†æ‰€æœ‰epoch
    epoch_losses = []  # è®°å½•æ¯ä¸ªepochçš„æŸå¤±

    try:
        for epoch in range(args.epochs):
            # ğŸ” è®°å½•epochå¼€å§‹
            monitor.log_epoch_start(epoch, args.epochs)

            # è®°å½•å½“å‰epochçš„å¼€å§‹ä¿¡æ¯
            logging.info(f"Starting epoch {epoch}/{args.epochs}:")
            # åˆ›å»ºè¿›åº¦æ¡ï¼Œæ˜¾ç¤ºå½“å‰epochçš„è®­ç»ƒè¿›åº¦
            pbar = tqdm(dataloader, desc=f"Epoch {epoch}")

            epoch_loss_sum = 0.0
            batch_count = 0

            # éå†æ•°æ®åŠ è½½å™¨ä¸­çš„æ¯ä¸ªbatch
            for i, (images, labels) in enumerate(pbar):
                # å°†å›¾åƒæ•°æ®ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ï¼ˆGPU/CPU/MPSï¼‰
                images = images.to(device)
                # å°†æ ‡ç­¾æ•°æ®ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
                labels = labels.to(device)
                # ä¸ºå½“å‰batchçš„æ¯å¼ å›¾åƒéšæœºé‡‡æ ·æ—¶é—´æ­¥
                t = diffusion.sample_timesteps(images.shape[0]).to(device)
                # å¯¹å›¾åƒè¿›è¡Œå‰å‘åŠ å™ªï¼Œè·å¾—åŠ å™ªå›¾åƒx_tå’Œå¯¹åº”çš„çœŸå®å™ªå£°
                x_t, noise = diffusion.noise_images(images, t)
                # å®ç°Classifier-Free Guidanceè®­ç»ƒç­–ç•¥ï¼š
                # 10%çš„æ—¶é—´ä¸¢å¼ƒæ¡ä»¶æ ‡ç­¾ï¼Œè®­ç»ƒæ— æ¡ä»¶ç”Ÿæˆèƒ½åŠ›
                # è¿™ä½¿å¾—æ¨¡å‹æ—¢èƒ½è¿›è¡Œæ¡ä»¶ç”Ÿæˆï¼Œä¹Ÿèƒ½è¿›è¡Œæ— æ¡ä»¶ç”Ÿæˆ
                if np.random.random() < 0.1:
                    labels = None
                # ä½¿ç”¨æ¨¡å‹é¢„æµ‹å™ªå£°ï¼šè¾“å…¥åŠ å™ªå›¾åƒã€æ—¶é—´æ­¥å’Œæ¡ä»¶æ ‡ç­¾
                predicted_noise = model(x_t, t, labels)
                # è®¡ç®—é¢„æµ‹å™ªå£°ä¸çœŸå®å™ªå£°ä¹‹é—´çš„å‡æ–¹è¯¯å·®æŸå¤±
                loss = mse(noise, predicted_noise)

                # æ¸…é›¶ä¼˜åŒ–å™¨çš„æ¢¯åº¦ç¼“å­˜
                optimizer.zero_grad()
                # åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦
                loss.backward()
                # æ›´æ–°æ¨¡å‹å‚æ•°
                optimizer.step()
                # æ›´æ–°EMAæ¨¡å‹ï¼šä½¿ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡å¹³æ»‘ä¸»æ¨¡å‹çš„å‚æ•°
                # è¿™æœ‰åŠ©äºæå‡ç”Ÿæˆæ ·æœ¬çš„è´¨é‡å’Œç¨³å®šæ€§
                ema.step_ema(ema_model, model)

                # è®°å½•æŸå¤±å’Œæ‰¹æ¬¡ä¿¡æ¯
                loss_value = loss.item()
                epoch_loss_sum += loss_value
                batch_count += 1

                # ğŸ” è®°å½•æ‰¹æ¬¡è¿›åº¦ï¼ˆä½¿ç”¨ç›‘æ§å™¨ï¼‰
                monitor.log_batch_progress(i, len(dataloader), loss_value, args.lr)

                # åœ¨è¿›åº¦æ¡ä¸­æ˜¾ç¤ºå½“å‰çš„MSEæŸå¤±å€¼
                pbar.set_postfix(MSE=loss_value, Device=device)
                # å°†æŸå¤±å€¼è®°å½•åˆ°TensorBoardï¼Œç”¨äºå¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹
                logger.add_scalar("MSE", loss_value, global_step=epoch * l + i)

            # è®¡ç®—epochå¹³å‡æŸå¤±
            avg_epoch_loss = epoch_loss_sum / batch_count if batch_count > 0 else 0.0
            epoch_losses.append(avg_epoch_loss)

            # ğŸ” è®°å½•epochç»“æŸ
            monitor.log_epoch_end(epoch, avg_epoch_loss)
            
            # ğŸ›¡ï¸ æ›´æ–°æ—©åœç›‘æ§å™¨
            should_stop, stop_reason = early_stopping.update(avg_epoch_loss, epoch)

            # æ¯5ä¸ªepochæ‰“å°ä¸€æ¬¡è¯¦ç»†çš„ç›‘æ§çŠ¶æ€
            if epoch % 5 == 0:
                print("\n" + early_stopping.get_status_summary(epoch))

            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰‹åŠ¨ç¡®è®¤åœæ­¢
            manual_stop, manual_reason = early_stopping.manual_stop_check()

            stop_triggered = should_stop or manual_stop
            final_stop_reason = manual_reason if manual_stop else stop_reason

            # å½“æ£€æµ‹åˆ°åœæ­¢æ¡ä»¶æˆ–è¾¾åˆ°é‡‡æ ·é—´éš”æ—¶ä¿å­˜æ ·æœ¬ä¸æ£€æŸ¥ç‚¹
            if stop_triggered or epoch % 10 == 0:
                labels = torch.arange(10).long().to(device)
                monitor.log_sampling_start(len(labels))

                sampled_images = diffusion.sample(model, n=len(labels), labels=labels)
                ema_sampled_images = diffusion.sample(ema_model, n=len(labels), labels=labels)

                main_image_path = os.path.join("results", args.run_name, f"{epoch}.jpg")
                ema_image_path = os.path.join("results", args.run_name, f"{epoch}_ema.jpg")

                save_images(sampled_images, main_image_path, nrow=len(labels))
                save_images(ema_sampled_images, ema_image_path, nrow=len(labels))

                monitor.log_sampling_end(len(labels), f"{main_image_path}, {ema_image_path}")

                torch.save(model.state_dict(), os.path.join("models", args.run_name, f"ckpt.pt"))
                torch.save(ema_model.state_dict(), os.path.join("models", args.run_name, f"ema_ckpt.pt"))
                torch.save(optimizer.state_dict(), os.path.join("models", args.run_name, f"optim.pt"))

                print(f"âœ… Epoch {epoch}: æ¨¡å‹æ£€æŸ¥ç‚¹å·²ä¿å­˜")

            if stop_triggered:
                reason_to_report = final_stop_reason or "æ—©åœæ¡ä»¶è§¦å‘"
                print(f"\nğŸ› è®­ç»ƒåœæ­¢æ¡ä»¶å·²è§¦å‘: {reason_to_report}")
                early_stopping.save_checkpoint_with_metadata(
                    model, ema_model, optimizer, epoch, avg_epoch_loss,
                    os.path.join("models", args.run_name), args.run_name
                )
                early_stopping.save_loss_plot(
                    os.path.join("results", args.run_name), args.run_name
                )
                break

    except KeyboardInterrupt:
        print("\nâš ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        monitor.print_training_summary(args.epochs)
        print("ğŸ’¾ æ­£åœ¨ä¿å­˜å½“å‰è¿›åº¦...")

        # ä¿å­˜ä¸­æ–­æ—¶çš„æ¨¡å‹çŠ¶æ€
        torch.save(model.state_dict(), os.path.join("models", args.run_name, f"interrupted_ckpt.pt"))
        torch.save(ema_model.state_dict(), os.path.join("models", args.run_name, f"interrupted_ema_ckpt.pt"))
        torch.save(optimizer.state_dict(), os.path.join("models", args.run_name, f"interrupted_optim.pt"))
        
        # ğŸ›¡ï¸ ä¿å­˜æ—©åœç›‘æ§å™¨æ•°æ®
        try:
            early_stopping.save_loss_plot(
                os.path.join("results", args.run_name), f"{args.run_name}_interrupted"
            )
            print("ğŸ“ˆ è®­ç»ƒåˆ†æå›¾è¡¨å·²ä¿å­˜")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜åˆ†æå›¾è¡¨æ—¶å‡ºé”™: {e}")
        
        print("âœ… ä¸­æ–­çŠ¶æ€å·²ä¿å­˜")

    except Exception as e:
        print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        monitor.print_training_summary(args.epochs)
        raise

    finally:
        # ğŸ” æ‰“å°æœ€ç»ˆçš„è®­ç»ƒæ€»ç»“
        print("\nğŸ‰ è®­ç»ƒå®Œæˆ!")
        monitor.print_training_summary(args.epochs)
        
        # ğŸ›¡ï¸ æ‰“å°æ—©åœç›‘æ§å™¨æ€»ç»“
        if 'early_stopping' in locals():
            print("\nğŸ›¡ï¸ æ—©åœç›‘æ§å™¨æ€»ç»“:")
            if len(early_stopping.loss_history) > 0:
                print(f"   ğŸ“‰ æ€»å…±è®°å½•äº† {len(early_stopping.loss_history)} ä¸ªepochçš„loss")
                print(f"   ğŸ† æœ€ä½³loss: {early_stopping.best_loss:.6f} (Epoch {early_stopping.best_epoch})")
                print(f"   ğŸ¯ æ”¶æ•›çŠ¶æ€: {'\u5df2æ”¶æ•›' if early_stopping.is_converged else '\u672aæ”¶æ•›'}")
            
            # æœ€ç»ˆä¿å­˜lossåˆ†æå›¾
            try:
                early_stopping.save_loss_plot(
                    os.path.join("results", args.run_name), f"{args.run_name}_final"
                )
                print("   ğŸ“ˆ æœ€ç»ˆåˆ†æå›¾è¡¨å·²ä¿å­˜")
            except Exception as e:
                print(f"   âš ï¸ ä¿å­˜æœ€ç»ˆåˆ†æå›¾è¡¨æ—¶å‡ºé”™: {e}")


def get_optimal_device():
    """
    è·å–æœ€ä¼˜çš„è®¡ç®—è®¾å¤‡ï¼Œä¼˜å…ˆçº§ï¼šCUDA > CPU
    è¿”å›: (device_name, device_object, device_info)
    """
    import time

    # ä¼˜å…ˆä½¿ç”¨CUDA
    if torch.cuda.is_available():
        device = torch.device("cuda")
        gpu_name = torch.cuda.get_device_name()
        print(f"ğŸ”¥ Using CUDA: {gpu_name}")
        
        # æ˜¾ç¤ºCUDAç›¸å…³ä¿¡æ¯
        print(f"   PyTorch version: {torch.__version__}")
        print(f"   CUDA version: {torch.version.cuda}")
        print(f"   GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        
        # æµ‹è¯•CUDAæ€§èƒ½
        try:
            test_tensor = torch.randn(1000, 1000, device=device)
            torch.cuda.synchronize()  # ç¡®ä¿æ“ä½œå®Œæˆ
            start_time = time.time()
            _ = torch.matmul(test_tensor, test_tensor)
            torch.cuda.synchronize()
            end_time = time.time()
            print(f"   CUDA performance test: {(end_time - start_time)*1000:.2f}ms")
        except Exception as e:
            print(f"   âš ï¸  CUDA test failed: {e}")
        
        return "cuda", device, f"NVIDIA GPU: {gpu_name}"

    # å›é€€åˆ°CPU
    device = torch.device("cpu")
    print("ğŸ’» Using CPU")
    print("   âš ï¸  CUDA not available - training will be significantly slower")
    print("   ğŸ’¡ For GPU acceleration, ensure CUDA-compatible GPU and drivers are installed")

    return "cpu", device, "CPU (fallback)"


def optimize_batch_size_for_device(device_name, image_size, base_batch_size=64):
    """
    æ ¹æ®è®¾å¤‡ç±»å‹ä¼˜åŒ–æ‰¹æ¬¡å¤§å°
    å‚æ•°:
        device_name: è®¾å¤‡åç§° ("cuda", "cpu")
        base_batch_size: åŸºç¡€æ‰¹æ¬¡å¤§å°
    è¿”å›:
        ä¼˜åŒ–åçš„æ‰¹æ¬¡å¤§å°
    """
    if device_name == "cuda":
        gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3

        if image_size <= 32:
            if gpu_memory_gb >= 16.0:
                optimized_size = 256
            elif gpu_memory_gb >= 10.0:
                optimized_size = 192
            elif gpu_memory_gb >= 8.0:
                optimized_size = 128
            elif gpu_memory_gb >= 6.0:
                optimized_size = 96
            else:
                optimized_size = 64
        else:
            if gpu_memory_gb >= 16.0:
                optimized_size = 128
            elif gpu_memory_gb >= 10.0:
                optimized_size = 96
            elif gpu_memory_gb >= 8.0:
                optimized_size = 64
            elif gpu_memory_gb >= 6.0:
                optimized_size = 48
            else:
                optimized_size = max(32, base_batch_size // 2)

        print(f"   ğŸ“Š Optimized batch size for CUDA ({gpu_memory_gb:.1f}GB, image {image_size}px): {optimized_size}")
        return optimized_size

    if device_name == "mps":
        optimized_size = 96 if image_size <= 32 else 64
        print(f"   ğŸ“Š Optimized batch size for MPS (image {image_size}px): {optimized_size}")
        return optimized_size

    cpu_cores = os.cpu_count() or 4
    if image_size <= 32:
        optimized_size = max(16, min(32, cpu_cores * 2))
    else:
        optimized_size = max(8, min(16, cpu_cores))
    print(f"   ğŸ“Š Optimized batch size for CPU (image {image_size}px, cores {cpu_cores}): {optimized_size}")
    return optimized_size


def launch():
    """
    å¯åŠ¨è®­ç»ƒçš„ä¸»å‡½æ•°ï¼Œé…ç½®æ‰€æœ‰è®­ç»ƒå‚æ•°å¹¶å¼€å§‹è®­ç»ƒè¿‡ç¨‹
    ç°åœ¨æ”¯æŒæ™ºèƒ½è®¾å¤‡é€‰æ‹©ï¼Œä¼˜å…ˆä½¿ç”¨CUDAåŠ é€Ÿ
    """
    # å¯¼å…¥å‘½ä»¤è¡Œå‚æ•°è§£æå™¨
    import argparse
    import os
    # åˆ›å»ºå‚æ•°è§£æå™¨å®ä¾‹
    parser = argparse.ArgumentParser()
    parser.add_argument('--dataset_path', type=str, default=None, help='Path to dataset')
    parser.add_argument('--epochs', type=int, default=300, help='Number of epochs')
    parser.add_argument('--batch_size', type=int, default=None, help='Batch size (auto if not specified)')
    parser.add_argument('--lr', type=float, default=3e-4, help='Learning rate')
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parser.parse_args()

    print("ğŸ¯ DDPM Conditional Training Setup")
    print("=" * 50)

    # è®¾ç½®å®éªŒè¿è¡Œåç§°ï¼Œç”¨äºåŒºåˆ†ä¸åŒçš„è®­ç»ƒå®éªŒ
    args.run_name = "DDPM_conditional"
    # è®¾ç½®å›¾åƒå°ºå¯¸ï¼ˆ32x32åƒç´ ï¼ŒåŒ¹é…ç²¾ç®€æ•°æ®é›†å¹¶åŠ å¿«è¿­ä»£ï¼‰
    args.image_size = 32
    # è®¾ç½®ç±»åˆ«æ•°é‡ï¼ˆCIFAR-10æœ‰10ä¸ªç±»åˆ«ï¼‰
    args.num_classes = 10
    
    # æ•°æ®é›†è·¯å¾„é…ç½® - æ”¯æŒLinuxç¯å¢ƒ
    if args.dataset_path is None:
        # é»˜è®¤æ•°æ®é›†è·¯å¾„åˆ—è¡¨ï¼ˆä¼˜å…ˆçº§é¡ºåºï¼‰
        possible_paths = [
            "./datasets/cifar10-32/train",
            "./data/cifar10-32/train",
            "../datasets/cifar10-32/train",
            "./datasets/cifar10-64/train",
            "./data/cifar10-64/train",
            "../datasets/cifar10-64/train",
            "/home/ryuichi/datasets/cifar10-32/train",
            "/home/ryuichi/datasets/cifar10-64/train",
            "/tmp/cifar10-32/train",
            "/tmp/cifar10-64/train"
        ]
        
        # æŸ¥æ‰¾å­˜åœ¨çš„æ•°æ®é›†è·¯å¾„
        dataset_found = False
        for path in possible_paths:
            if os.path.exists(path):
                args.dataset_path = path
                dataset_found = True
                break
        
        if not dataset_found:
            print("âš ï¸  æœªæ‰¾åˆ°æ•°æ®é›†ï¼")
            print("ğŸ’¡ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹å¼è§£å†³ï¼š")
            print("   1. ä½¿ç”¨ --dataset_path å‚æ•°æŒ‡å®šæ•°æ®é›†è·¯å¾„")
            print("   2. å°†æ•°æ®é›†æ”¾åœ¨ä»¥ä¸‹ä½ç½®ä¹‹ä¸€ï¼š")
            for path in possible_paths[:3]:
                print(f"      - {path}")
            print("   3. ä½¿ç”¨CIFAR-10è‡ªåŠ¨ä¸‹è½½ï¼ˆä¿®æ”¹utils.pyï¼‰")
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªè·¯å¾„ä½œä¸ºé»˜è®¤å€¼ï¼Œä½†ä¼šæé†’ç”¨æˆ·
            args.dataset_path = possible_paths[0]
    
    # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼ï¼ˆåŒºåˆ«äºæ¨ç†æ¨¡å¼ï¼‰
    args.train = True

    # ğŸš€ æ™ºèƒ½è®¾å¤‡é€‰æ‹©å’Œé…ç½®
    device_name, _, device_info = get_optimal_device()  # device_objåœ¨è¿™é‡Œä¸éœ€è¦ä½¿ç”¨
    args.device = device_name

    # ğŸ“Š æ ¹æ®è®¾å¤‡ä¼˜åŒ–æ‰¹æ¬¡å¤§å°
    if args.batch_size is None:
        base_batch_size = 64
        args.batch_size = optimize_batch_size_for_device(device_name, args.image_size, base_batch_size)

    # ğŸ”§ CUDAç‰¹å®šçš„ä¼˜åŒ–è®¾ç½®
    if device_name == "cuda":
        # å¯ç”¨CUDAä¼˜åŒ–
        torch.backends.cudnn.benchmark = True  # ä¼˜åŒ–å›ºå®šå°ºå¯¸è¾“å…¥çš„æ€§èƒ½
        torch.backends.cudnn.deterministic = False  # ä¸ºäº†æ€§èƒ½æ”¾å¼ƒä¸€äº›ç¡®å®šæ€§
        print("   ğŸ”§ Enabled CUDA optimizations (cudnn.benchmark=True)")
        
        # æ ¹æ®æ˜¾å­˜è°ƒæ•´å…¶ä»–å‚æ•°
        gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3
        if gpu_memory_gb >= 8.0 and args.batch_size < 8:
            old_batch_size = args.batch_size
            args.batch_size = min(8, args.batch_size * 2)
            print(f"   ğŸ“ˆ Increased batch size from {old_batch_size} to {args.batch_size} for large GPU")

    print(f"\nğŸ“‹ Training Configuration:")
    print(f"   ğŸ¯ Run name: {args.run_name}")
    print(f"   ğŸ”„ Epochs: {args.epochs}")
    print(f"   ğŸ“¦ Batch size: {args.batch_size}")
    print(f"   ğŸ–¼ï¸  Image size: {args.image_size}x{args.image_size}")
    print(f"   ğŸ·ï¸  Classes: {args.num_classes}")
    print(f"   ğŸ“š Dataset: {args.dataset_path}")
    print(f"   ğŸ›ï¸  Device: {device_info}")
    print(f"   ğŸ“ˆ Learning rate: {args.lr}")
    print("=" * 50)

    # å¼€å§‹è®­ç»ƒè¿‡ç¨‹
    train(args)


# ç¨‹åºå…¥å£ç‚¹ï¼šå½“ç›´æ¥è¿è¡Œæ­¤è„šæœ¬æ—¶æ‰§è¡Œ
if __name__ == '__main__':
    # å¯åŠ¨è®­ç»ƒè¿‡ç¨‹
    launch()
    # ä»¥ä¸‹æ˜¯æ¨ç†ä»£ç ç¤ºä¾‹ï¼ˆå·²æ³¨é‡Šï¼‰ï¼š
    # ç”¨äºåŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å¹¶ç”Ÿæˆå›¾åƒ
    # device = "cuda"
    # # åˆ›å»ºæ¨¡å‹å®ä¾‹
    # model = UNet_conditional(num_classes=10).to(device)
    # # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡
    # ckpt = torch.load("./models/DDPM_conditional/ckpt.pt")
    # model.load_state_dict(ckpt)
    # # åˆ›å»ºæ‰©æ•£è¿‡ç¨‹ç®¡ç†å™¨
    # diffusion = Diffusion(img_size=64, device=device)
    # # è®¾ç½®ç”Ÿæˆå›¾åƒçš„æ•°é‡
    # n = 8
    # # åˆ›å»ºæ¡ä»¶æ ‡ç­¾ï¼ˆç”Ÿæˆ8å¼ ç±»åˆ«ä¸º6çš„å›¾åƒï¼‰
    # y = torch.Tensor([6] * n).long().to(device)
    # # ç”Ÿæˆå›¾åƒï¼ˆcfg_scale=0è¡¨ç¤ºæ— Classifier-Free Guidanceï¼‰
    # x = diffusion.sample(model, n, y, cfg_scale=0)
    # # æ˜¾ç¤ºç”Ÿæˆçš„å›¾åƒ
    # plot_images(x)
