#!/usr/bin/env python3
"""
æ—©åœç›‘æ§å™¨ (Early Stopping Monitor)
ç”¨äºç›‘æ§DDPMè®­ç»ƒè¿‡ç¨‹ä¸­çš„losså˜åŒ–ï¼Œæ£€æµ‹æ”¶æ•›å¹¶å®ç°ä¼˜é›…åœæ­¢
"""

# import numpy as np  # ä½¿ç”¨åŸç”ŸPythonå®ç°
import torch
import os
import time
from datetime import datetime
from collections import deque
# import matplotlib.pyplot as plt  # å¯é€‰ä¾èµ–
import logging


class EarlyStoppingMonitor:
    """
    æ—©åœç›‘æ§å™¨
    ç›‘æ§è®­ç»ƒæŸå¤±çš„å˜åŒ–è¶‹åŠ¿ï¼Œåœ¨æ£€æµ‹åˆ°æ”¶æ•›æ—¶æä¾›åœæ­¢å»ºè®®
    """
    
    def __init__(self, 
                 patience=20,           # å®¹å¿æ²¡æœ‰æ”¹è¿›çš„epochæ•°
                 min_delta=1e-6,        # æœ€å°æ”¹è¿›é˜ˆå€¼
                 smoothing_window=10,   # å¹³æ»‘çª—å£å¤§å°
                 convergence_threshold=1e-4,  # æ”¶æ•›é˜ˆå€¼ï¼ˆé»˜è®¤æ›´å®½æ¾ï¼‰
                 auto_stop=False,       # æ˜¯å¦è‡ªåŠ¨åœæ­¢
                 save_plots=True):      # æ˜¯å¦ä¿å­˜lossæ›²çº¿å›¾
        
        self.patience = patience
        self.min_delta = min_delta
        self.smoothing_window = smoothing_window
        self.convergence_threshold = convergence_threshold
        self.auto_stop = auto_stop
        self.save_plots = save_plots
        
        # ç›‘æ§çŠ¶æ€
        self.loss_history = []
        self.smoothed_losses = deque(maxlen=smoothing_window)
        self.best_loss = float('inf')
        self.best_epoch = 0
        self.patience_counter = 0
        self.is_converged = False
        self.should_stop = False
        self.pending_manual_stop_reason = None

        # ç»Ÿè®¡ä¿¡æ¯
        self.convergence_detection_history = []
        self.improvement_history = []

        # åˆ¤æ–­å½“å‰æ˜¯å¦å¤„äºäº¤äº’å¼ç»ˆç«¯ï¼Œéäº¤äº’ç¯å¢ƒä¸‹ä¸è§¦å‘ input
        try:
            import sys
            self.interactive_session = sys.stdin.isatty()
        except Exception:
            self.interactive_session = False
        
        print(f"ğŸ›¡ï¸ æ—©åœç›‘æ§å™¨å·²å¯ç”¨")
        print(f"   ğŸ“Š å‚æ•°é…ç½®:")
        print(f"      - è€å¿ƒå€¼: {patience} epochs")
        print(f"      - æœ€å°æ”¹è¿›: {min_delta}")
        print(f"      - å¹³æ»‘çª—å£: {smoothing_window}")
        print(f"      - æ”¶æ•›é˜ˆå€¼: {convergence_threshold}")
        print(f"      - è‡ªåŠ¨åœæ­¢: {'æ˜¯' if auto_stop else 'å¦'}")
    
    def update(self, current_loss, epoch):
        """
        æ›´æ–°ç›‘æ§çŠ¶æ€
        å‚æ•°:
            current_loss: å½“å‰epochçš„losså€¼
            epoch: å½“å‰epochæ•°
        è¿”å›:
            (should_stop, reason): (æ˜¯å¦åº”è¯¥åœæ­¢, åœæ­¢åŸå› )
        """
        self.loss_history.append(current_loss)
        self.smoothed_losses.append(current_loss)
        
        # è®¡ç®—å¹³æ»‘åçš„loss
        current_smoothed_loss = sum(self.smoothed_losses) / len(self.smoothed_losses)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ”¹è¿›
        improved = False
        if current_smoothed_loss < self.best_loss - self.min_delta:
            self.best_loss = current_smoothed_loss
            self.best_epoch = epoch
            self.patience_counter = 0
            improved = True
        else:
            self.patience_counter += 1
        
        self.improvement_history.append(improved)
        
        # æ”¶æ•›æ£€æµ‹
        convergence_detected = self._detect_convergence()
        self.convergence_detection_history.append(convergence_detected)
        
        # å†³å®šæ˜¯å¦åœæ­¢
        stop_reason = None
        
        if convergence_detected and not self.is_converged:
            self.is_converged = True
            stop_reason = "æ”¶æ•›æ£€æµ‹"
            print(f"\nğŸ¯ æ£€æµ‹åˆ°æ”¶æ•›! (Epoch {epoch})")
            print(f"   ğŸ“‰ å½“å‰loss: {current_loss:.6f}")
            print(f"   ğŸ“Š å¹³æ»‘loss: {current_smoothed_loss:.6f}")
            print(f"   ğŸ† æœ€ä½³loss: {self.best_loss:.6f} (Epoch {self.best_epoch})")
            
            if self.auto_stop:
                self.should_stop = True
            else:
                self.pending_manual_stop_reason = stop_reason
                print(f"   â“ æ˜¯å¦è¦åœæ­¢è®­ç»ƒ? (è‡ªåŠ¨åœæ­¢å·²ç¦ç”¨)")

        elif self.patience_counter >= self.patience:
            stop_reason = f"è€å¿ƒå€¼è€—å°½ ({self.patience} epochsæ— æ”¹è¿›)"
            print(f"\nâ° è§¦å‘æ—©åœæ¡ä»¶! (Epoch {epoch})")
            print(f"   ğŸ“‰ å½“å‰loss: {current_loss:.6f}")
            print(f"   ğŸ† æœ€ä½³loss: {self.best_loss:.6f} (Epoch {self.best_epoch})")
            print(f"   â³ æ— æ”¹è¿›epochs: {self.patience_counter}")

            if self.auto_stop:
                self.should_stop = True
            else:
                self.pending_manual_stop_reason = stop_reason
                print(f"   â“ æ˜¯å¦è¦åœæ­¢è®­ç»ƒ? (è‡ªåŠ¨åœæ­¢å·²ç¦ç”¨)")

        return self.should_stop, stop_reason
    
    def _detect_convergence(self):
        """æ£€æµ‹æ˜¯å¦æ”¶æ•›"""
        if len(self.smoothed_losses) < self.smoothing_window:
            return False
        
        # è®¡ç®—losså˜åŒ–çš„æ–¹å·®
        recent_losses = list(self.smoothed_losses)
        if len(recent_losses) < 2:
            return False
            
        # è®¡ç®—æ–¹å·®
        mean_loss = sum(recent_losses) / len(recent_losses)
        loss_variance = sum((x - mean_loss) ** 2 for x in recent_losses) / len(recent_losses)
        
        # è®¡ç®—losså˜åŒ–çš„è¶‹åŠ¿(ç®€å•çš„çº¿æ€§æ‹Ÿåˆ)
        if len(recent_losses) >= 3:
            n = len(recent_losses)
            x_values = list(range(n))
            sum_x = sum(x_values)
            sum_y = sum(recent_losses)
            sum_xy = sum(x * y for x, y in zip(x_values, recent_losses))
            sum_x2 = sum(x * x for x in x_values)
            
            # è®¡ç®—æ–œç‡(è¶‹åŠ¿)
            if n * sum_x2 - sum_x * sum_x != 0:
                trend = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x * sum_x)
            else:
                trend = 0
                
            # ä½¿ç”¨åŒæ—¶çº¦æŸè¶‹åŠ¿ä¸æ–¹å·®ï¼›ä¸ºäº†å…¼å®¹ä¸åŒé‡çº§ï¼Œåœ¨é˜ˆå€¼ä¸Šåº”ç”¨ç›¸å¯¹å°ºåº¦
            dynamic_threshold = self.convergence_threshold
            if self.best_loss not in (0, float('inf')):
                dynamic_threshold = max(dynamic_threshold, abs(self.best_loss) * 1e-3)

            return abs(trend) < dynamic_threshold and loss_variance < (dynamic_threshold ** 2)

        return False
    
    def get_status_summary(self, epoch):
        """è·å–çŠ¶æ€æ‘˜è¦"""
        if len(self.loss_history) == 0:
            return "ç›‘æ§å™¨å°šæœªæ¥æ”¶åˆ°lossæ•°æ®"
        
        current_loss = self.loss_history[-1]
        current_smoothed = sum(self.smoothed_losses) / len(self.smoothed_losses) if self.smoothed_losses else current_loss
        
        status = f"ğŸ“Š ç›‘æ§çŠ¶æ€ (Epoch {epoch}):\n"
        status += f"   ğŸ“‰ å½“å‰loss: {current_loss:.6f}\n"
        status += f"   ğŸ“ˆ å¹³æ»‘loss: {current_smoothed:.6f}\n"
        status += f"   ğŸ† æœ€ä½³loss: {self.best_loss:.6f} (Epoch {self.best_epoch})\n"
        status += f"   â³ è€å¿ƒè®¡æ•°: {self.patience_counter}/{self.patience}\n"
        status += f"   ğŸ¯ æ”¶æ•›çŠ¶æ€: {'å·²æ”¶æ•›' if self.is_converged else 'è®­ç»ƒä¸­'}\n"
        
        if len(self.loss_history) >= self.smoothing_window:
            recent_losses = list(self.smoothed_losses)
            mean_loss = sum(recent_losses) / len(recent_losses)
            recent_variance = sum((x - mean_loss) ** 2 for x in recent_losses) / len(recent_losses)
            status += f"ã€€ã€€ğŸ“† æœ€è¿‘æ–¹å·®: {recent_variance:.8f}\n"
        
        return status
    
    def save_loss_plot(self, save_path, run_name):
        """ä¿å­˜lossæ›²çº¿å›¾"""
        if not self.save_plots or len(self.loss_history) < 2:
            return
        
        try:
            import matplotlib.pyplot as plt
            plt.figure(figsize=(12, 8))
            
            # ç»˜åˆ¶åŸå§‹loss
            epochs = range(len(self.loss_history))
            plt.subplot(2, 1, 1)
            plt.plot(epochs, self.loss_history, 'b-', alpha=0.6, label='åŸå§‹Loss')
            
            # ç»˜åˆ¶å¹³æ»‘åçš„loss
            if len(self.loss_history) >= self.smoothing_window:
                smoothed_all = []
                for i in range(len(self.loss_history)):
                    start_idx = max(0, i - self.smoothing_window + 1)
                    end_idx = i + 1
                    window_data = self.loss_history[start_idx:end_idx]
                    smoothed_all.append(sum(window_data) / len(window_data))
                
                plt.plot(epochs, smoothed_all, 'r-', linewidth=2, label=f'å¹³æ»‘Loss (çª—å£={self.smoothing_window})')
            
            # æ ‡è®°æœ€ä½³ç‚¹
            plt.axvline(x=self.best_epoch, color='g', linestyle='--', alpha=0.7, label=f'æœ€ä½³Epoch ({self.best_epoch})')
            plt.axhline(y=self.best_loss, color='g', linestyle='--', alpha=0.7)
            
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.title(f'{run_name} - è®­ç»ƒLossæ›²çº¿')
            plt.legend()
            plt.grid(True, alpha=0.3)
            
            # ç»˜åˆ¶æ”¶æ•›æ£€æµ‹å†å²
            plt.subplot(2, 1, 2)
            if self.convergence_detection_history:
                convergence_epochs = [i for i, detected in enumerate(self.convergence_detection_history) if detected]
                if convergence_epochs:
                    plt.scatter(convergence_epochs, [1] * len(convergence_epochs), 
                              c='red', s=50, marker='o', label='æ”¶æ•›æ£€æµ‹ç‚¹', zorder=5)
            
            improvement_epochs = [i for i, improved in enumerate(self.improvement_history) if improved]
            if improvement_epochs:
                plt.scatter(improvement_epochs, [0.5] * len(improvement_epochs), 
                          c='green', s=30, marker='^', label='æ”¹è¿›ç‚¹', alpha=0.7, zorder=4)
            
            plt.ylim(-0.1, 1.1)
            plt.xlabel('Epoch')
            plt.ylabel('äº‹ä»¶')
            plt.title('è®­ç»ƒäº‹ä»¶æ—¶é—´çº¿')
            plt.legend()
            plt.grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾ç‰‡
            plot_filename = f"{run_name}_loss_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
            plot_path = os.path.join(save_path, plot_filename)
            plt.savefig(plot_path, dpi=150, bbox_inches='tight')
            plt.close()
            
            print(f"ğŸ“Š Lossåˆ†æå›¾å·²ä¿å­˜: {plot_path}")
            
        except ImportError:
            print("âš ï¸ matplotlibä¸å¯ç”¨ï¼Œè·³è¿‡å›¾è¡¨ä¿å­˜")
            # ä¿å­˜æ–‡æœ¬ç‰ˆæœ¬çš„åˆ†ææŠ¥å‘Š
            self._save_text_report(save_path, run_name)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜losså›¾è¡¨æ—¶å‡ºé”™: {e}")
            self._save_text_report(save_path, run_name)
    
    def save_checkpoint_with_metadata(self, model, ema_model, optimizer, epoch, loss, save_dir, run_name):
        """ä¿å­˜å¸¦æœ‰å…ƒæ•°æ®çš„æ£€æŸ¥ç‚¹"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # å‡†å¤‡å…ƒæ•°æ®
        metadata = {
            'epoch': epoch,
            'loss': loss,
            'best_loss': self.best_loss,
            'best_epoch': self.best_epoch,
            'is_converged': self.is_converged,
            'patience_counter': self.patience_counter,
            'loss_history': self.loss_history,
            'timestamp': timestamp,
            'monitor_config': {
                'patience': self.patience,
                'min_delta': self.min_delta,
                'smoothing_window': self.smoothing_window,
                'convergence_threshold': self.convergence_threshold
            }
        }
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        checkpoint = {
            'model_state_dict': model.state_dict(),
            'ema_model_state_dict': ema_model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'metadata': metadata
        }
        
        # å†³å®šæ–‡ä»¶å
        if self.is_converged:
            filename = f"{run_name}_converged_{timestamp}.pt"
        elif self.patience_counter >= self.patience:
            filename = f"{run_name}_early_stopped_{timestamp}.pt"
        else:
            filename = f"{run_name}_best_checkpoint.pt"
        
        checkpoint_path = os.path.join(save_dir, filename)
        torch.save(checkpoint, checkpoint_path)
        
        print(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")
        
        # å¦‚æœæ˜¯æœ€ä½³æ¨¡å‹ï¼Œä¹Ÿä¿å­˜ä¸€ä¸ªç®€å•çš„ç‰ˆæœ¬
        if epoch == self.best_epoch:
            best_path = os.path.join(save_dir, f"{run_name}_best_model.pt")
            torch.save(checkpoint, best_path)
            print(f"ğŸ† æœ€ä½³æ¨¡å‹å·²ä¿å­˜: {best_path}")
        
        return checkpoint_path
    
    def _save_text_report(self, save_path, run_name):
        """ä¿å­˜æ–‡æœ¬ç‰ˆæœ¬çš„åˆ†ææŠ¥å‘Š"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            report_filename = f"{run_name}_analysis_{timestamp}.txt"
            report_path = os.path.join(save_path, report_filename)
            
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(f"æ—©åœç›‘æ§å™¨åˆ†ææŠ¥å‘Š\n")
                f.write(f"=" * 50 + "\n")
                f.write(f"è®­ç»ƒåç§°: {run_name}\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                
                if len(self.loss_history) > 0:
                    f.write(f"è®­ç»ƒç»Ÿè®¡:\n")
                    f.write(f"  æ€»è®­ç»ƒepochs: {len(self.loss_history)}\n")
                    f.write(f"  æœ€åˆloss: {self.loss_history[-1]:.6f}\n")
                    f.write(f"  æœ€ä½³loss: {self.best_loss:.6f} (Epoch {self.best_epoch})\n")
                    f.write(f"  æ”¶æ•›çŠ¶æ€: {'\u5df2æ”¶æ•›' if self.is_converged else 'æœªæ”¶æ•›'}\n")
                    f.write(f"  è€å¿ƒè®¡æ•°: {self.patience_counter}/{self.patience}\n\n")
                    
                    # è®°å½•losså†å² (æœ€è¿‘100ä¸ªå€¼)
                    recent_losses = self.loss_history[-100:]
                    f.write(f"æœ€è¿‘losså€¼ (æœ€è¿‘{len(recent_losses)}ä¸ªepoch):\n")
                    for i, loss in enumerate(recent_losses):
                        epoch_num = len(self.loss_history) - len(recent_losses) + i
                        f.write(f"  Epoch {epoch_num}: {loss:.6f}")
                        if epoch_num == self.best_epoch:
                            f.write(" (æœ€ä½³)")
                        f.write("\n")
                    
                    # æ”¶æ•›æ£€æµ‹ç‚¹
                    if self.convergence_detection_history:
                        convergence_epochs = [i for i, detected in enumerate(self.convergence_detection_history) if detected]
                        if convergence_epochs:
                            f.write(f"\næ”¶æ•›æ£€æµ‹ç‚¹: {convergence_epochs}\n")
                    
                    # æ€§èƒ½åˆ†æ
                    if len(self.loss_history) >= 10:
                        initial_loss = self.loss_history[0]
                        final_loss = self.loss_history[-1]
                        improvement = initial_loss - final_loss
                        improvement_pct = (improvement / initial_loss) * 100 if initial_loss > 0 else 0
                        f.write(f"\næ€§èƒ½åˆ†æ:\n")
                        f.write(f"  åˆå§‹ loss: {initial_loss:.6f}\n")
                        f.write(f"  æœ€ç»ˆ loss: {final_loss:.6f}\n")
                        f.write(f"  ç»å¯¹æ”¹è¿›: {improvement:.6f}\n")
                        f.write(f"  ç›¸å¯¹æ”¹è¿›: {improvement_pct:.2f}%\n")
                
                f.write(f"\nç›‘æ§å™¨å‚æ•°:\n")
                f.write(f"  è€å¿ƒå€¼: {self.patience}\n")
                f.write(f"  æœ€å°æ”¹è¿›: {self.min_delta}\n")
                f.write(f"  å¹³æ»‘çª—å£: {self.smoothing_window}\n")
                f.write(f"  æ”¶æ•›é˜ˆå€¼: {self.convergence_threshold}\n")
            
            print(f"ğŸ“„ æ–‡æœ¬åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_path}")
            
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜æ–‡æœ¬æŠ¥å‘Šæ—¶å‡ºé”™: {e}")
    
    def manual_stop_check(self):
        """æ‰‹åŠ¨åœæ­¢æ£€æŸ¥ - åœ¨è®­ç»ƒå¾ªç¯ä¸­è°ƒç”¨"""
        if self.pending_manual_stop_reason and not self.auto_stop:
            try:
                if not self.interactive_session:
                    print("âš ï¸ å½“å‰ç¯å¢ƒéäº¤äº’å¼ï¼Œè·³è¿‡æ‰‹åŠ¨åœæ­¢ç¡®è®¤")
                    self.pending_manual_stop_reason = None
                    return False, None

                response = input(f"\nâ“ {self.pending_manual_stop_reason}ï¼Œæ˜¯å¦åœæ­¢è®­ç»ƒ? [y/N]: ").strip().lower()
                if response in ['y', 'yes', 'æ˜¯', 'åœæ­¢']:
                    self.should_stop = True
                    reason = self.pending_manual_stop_reason
                    self.pending_manual_stop_reason = None
                    return True, reason or "ç”¨æˆ·æ‰‹åŠ¨åœæ­¢"
                # ç”¨æˆ·é€‰æ‹©ç»§ç»­è®­ç»ƒ
                self.pending_manual_stop_reason = None
            except (EOFError, KeyboardInterrupt):
                # è¾“å…¥ä¸å¯ç”¨æˆ–è¢«ä¸­æ–­ï¼Œä¿ç•™çŠ¶æ€ä¾›ä¸‹æ¬¡æ£€æŸ¥
                print("âš ï¸ æ‰‹åŠ¨åœæ­¢ç¡®è®¤è¢«ä¸­æ–­ï¼Œç¨åå°†å†æ¬¡è¯¢é—®")
                return False, None

        return False, None


def integrate_early_stopping_to_training():
    """
    å°†æ—©åœç›‘æ§é›†æˆåˆ°ç°æœ‰è®­ç»ƒä»£ç çš„ç¤ºä¾‹
    """
    code_example = '''
    # åœ¨è®­ç»ƒå¼€å§‹å‰åˆ›å»ºç›‘æ§å™¨
    early_stopping = EarlyStoppingMonitor(
        patience=20,              # 20ä¸ªepochæ— æ”¹è¿›å°±æé†’
        min_delta=1e-6,          # æœ€å°æ”¹è¿›é˜ˆå€¼
        smoothing_window=10,     # 10ä¸ªepochçš„å¹³æ»‘çª—å£  
        auto_stop=False,         # æ‰‹åŠ¨ç¡®è®¤åœæ­¢
        save_plots=True          # ä¿å­˜åˆ†æå›¾è¡¨
    )
    
    # åœ¨è®­ç»ƒå¾ªç¯ä¸­ä½¿ç”¨
    for epoch in range(args.epochs):
        # ... è®­ç»ƒä»£ç  ...
        
        # è®¡ç®—epochå¹³å‡æŸå¤±
        avg_epoch_loss = epoch_loss_sum / batch_count
        
        # æ›´æ–°ç›‘æ§å™¨
        should_stop, stop_reason = early_stopping.update(avg_epoch_loss, epoch)
        
        # æ‰“å°çŠ¶æ€
        if epoch % 5 == 0:
            print(early_stopping.get_status_summary(epoch))
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
        if should_stop:
            print(f"\\nğŸ›‘ è®­ç»ƒåœæ­¢: {stop_reason}")
            # ä¿å­˜æœ€ç»ˆæ¨¡å‹
            early_stopping.save_checkpoint_with_metadata(
                model, ema_model, optimizer, epoch, avg_epoch_loss,
                os.path.join("models", args.run_name), args.run_name
            )
            # ä¿å­˜åˆ†æå›¾è¡¨
            early_stopping.save_loss_plot(
                os.path.join("results", args.run_name), args.run_name
            )
            break
        
        # æ‰‹åŠ¨åœæ­¢æ£€æŸ¥ï¼ˆä»…å½“æ£€æµ‹åˆ°æ”¶æ•›æ—¶ï¼‰
        manual_stop, manual_reason = early_stopping.manual_stop_check()
        if manual_stop:
            print(f"\\nğŸ›‘ è®­ç»ƒåœæ­¢: {manual_reason}")
            break
    '''
    
    return code_example


if __name__ == "__main__":
    # æ¼”ç¤ºç”¨æ³•
    print("ğŸ” æ—©åœç›‘æ§å™¨æ¼”ç¤º")
    print("=" * 50)
    
    # æ¨¡æ‹Ÿlossæ•°æ®
    np.random.seed(42)
    simulated_losses = []
    
    # æ¨¡æ‹Ÿæ”¶æ•›è¿‡ç¨‹
    for i in range(100):
        if i < 20:
            # åˆæœŸå¿«é€Ÿä¸‹é™
            loss = 2.0 * np.exp(-i/10) + 0.1 + np.random.normal(0, 0.05)
        elif i < 60:
            # ä¸­æœŸç¼“æ…¢ä¸‹é™
            loss = 0.3 * np.exp(-(i-20)/20) + 0.1 + np.random.normal(0, 0.02)
        else:
            # åæœŸæ”¶æ•›
            loss = 0.1 + np.random.normal(0, 0.005)
        
        simulated_losses.append(max(0.05, loss))  # ç¡®ä¿lossä¸ä¼šå¤ªå°
    
    # æµ‹è¯•ç›‘æ§å™¨
    monitor = EarlyStoppingMonitor(patience=15, auto_stop=True)
    
    for epoch, loss in enumerate(simulated_losses):
        should_stop, reason = monitor.update(loss, epoch)
        
        if epoch % 10 == 0:
            print(f"\\nEpoch {epoch}: Loss = {loss:.6f}")
            print(monitor.get_status_summary(epoch))
        
        if should_stop:
            print(f"\\nğŸ›‘ æ¨¡æ‹Ÿè®­ç»ƒåœæ­¢: {reason}")
            break
    
    print("\\nğŸ“Š æ¼”ç¤ºå®Œæˆ")
    print(integrate_early_stopping_to_training())
