#!/usr/bin/env python3
"""
MPSè®­ç»ƒç›‘æ§è„šæœ¬
ç”¨äºç›‘æ§DDPMåœ¨MPSè®¾å¤‡ä¸Šçš„è®­ç»ƒè¿‡ç¨‹ï¼ŒåŒ…æ‹¬æ€§èƒ½æŒ‡æ ‡å’Œèµ„æºä½¿ç”¨æƒ…å†µ
"""

import torch
import time
import psutil
import os
import subprocess
from datetime import datetime


class MPSTrainingMonitor:
    """MPSè®­ç»ƒç›‘æ§å™¨"""
    
    def __init__(self, device_name="mps"):
        self.device_name = device_name
        self.device = torch.device(device_name)
        self.start_time = None
        self.epoch_times = []
        self.batch_times = []
        self.memory_usage = []
        self.cpu_usage = []
        
    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        self.start_time = time.time()
        print(f"ğŸ” å¼€å§‹ç›‘æ§ {self.device_name.upper()} è®­ç»ƒè¿‡ç¨‹")
        print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
    def log_epoch_start(self, epoch, total_epochs):
        """è®°å½•epochå¼€å§‹"""
        self.epoch_start_time = time.time()
        print(f"\nğŸ“… Epoch {epoch}/{total_epochs} å¼€å§‹")
        print(f"â° æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")
        
    def log_batch_progress(self, batch_idx, total_batches, loss, lr=None):
        """è®°å½•æ‰¹æ¬¡è¿›åº¦"""
        current_time = time.time()
        
        # è®¡ç®—æ‰¹æ¬¡æ—¶é—´
        if hasattr(self, 'last_batch_time'):
            batch_time = current_time - self.last_batch_time
            self.batch_times.append(batch_time)
        self.last_batch_time = current_time
        
        # è·å–ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
        cpu_percent = psutil.cpu_percent()
        memory_info = psutil.virtual_memory()
        
        self.cpu_usage.append(cpu_percent)
        self.memory_usage.append(memory_info.percent)
        
        # æ¯10ä¸ªæ‰¹æ¬¡æ‰“å°ä¸€æ¬¡è¯¦ç»†ä¿¡æ¯
        if batch_idx % 10 == 0:
            window = self.batch_times[-10:]
            # åœ¨ç¬¬ä¸€ä¸ªæ‰¹æ¬¡æ—¶è¿˜æ²¡æœ‰batch_timesï¼Œé¿å…é™¤ä»¥0
            if len(window) > 0:
                avg_batch_time = sum(window) / len(window)
            else:
                # ä½¿ç”¨è‡ªepochå¼€å§‹çš„æ—¶é—´ä½œä¸ºç²—ç•¥ä¼°è®¡ï¼Œæˆ–å›é€€ä¸º0
                avg_batch_time = (current_time - getattr(self, 'epoch_start_time', current_time))
            
            print(f"  ğŸ“¦ Batch {batch_idx}/{total_batches}")
            print(f"    ğŸ“‰ Loss: {loss:.6f}")
            if lr:
                print(f"    ğŸ“ˆ LR: {lr:.2e}")
            print(f"    â±ï¸  Batch Time: {avg_batch_time:.3f}s")
            print(f"    ğŸ’¾ CPU: {cpu_percent:.1f}% | RAM: {memory_info.percent:.1f}%")
            
            # ä¼°ç®—å‰©ä½™æ—¶é—´ï¼ˆéœ€è¦è‡³å°‘ä¸€ä¸ªå·²æµ‹é‡çš„batchæ—¶é—´ï¼‰
            if len(window) > 0:
                remaining_batches = max(0, total_batches - batch_idx)
                eta_seconds = remaining_batches * avg_batch_time
                eta_minutes = eta_seconds / 60 if eta_seconds > 0 else 0
                print(f"    ğŸ• ETA: {eta_minutes:.1f} minutes")
    
    def log_epoch_end(self, epoch, avg_loss):
        """è®°å½•epochç»“æŸ"""
        epoch_time = time.time() - self.epoch_start_time
        self.epoch_times.append(epoch_time)
        
        print(f"\nâœ… Epoch {epoch} å®Œæˆ")
        print(f"  â±ï¸  è€—æ—¶: {epoch_time:.2f}s ({epoch_time/60:.1f} minutes)")
        print(f"  ğŸ“‰ å¹³å‡æŸå¤±: {avg_loss:.6f}")
        
        # è®¡ç®—å¹³å‡epochæ—¶é—´å’Œé¢„ä¼°æ€»æ—¶é—´
        if len(self.epoch_times) > 0:
            avg_epoch_time = sum(self.epoch_times) / len(self.epoch_times)
            print(f"  ğŸ“Š å¹³å‡Epochæ—¶é—´: {avg_epoch_time:.2f}s")
    
    def log_sampling_start(self, num_images):
        """è®°å½•é‡‡æ ·å¼€å§‹"""
        self.sampling_start_time = time.time()
        print(f"\nğŸ¨ å¼€å§‹ç”Ÿæˆ {num_images} å¼ å›¾åƒ...")
        
    def log_sampling_end(self, num_images, save_path):
        """è®°å½•é‡‡æ ·ç»“æŸ"""
        sampling_time = time.time() - self.sampling_start_time
        print(f"âœ… å›¾åƒç”Ÿæˆå®Œæˆ")
        print(f"  â±ï¸  è€—æ—¶: {sampling_time:.2f}s")
        if num_images > 0:
            print(f"  ğŸ–¼ï¸  æ¯å¼ å›¾åƒ: {sampling_time/num_images:.2f}s")
        print(f"  ğŸ’¾ ä¿å­˜è·¯å¾„: {save_path}")
    
    def get_system_info(self):
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        info = {
            "CPU": {
                "å‹å·": self._get_cpu_model(),
                "æ ¸å¿ƒæ•°": psutil.cpu_count(logical=False),
                "çº¿ç¨‹æ•°": psutil.cpu_count(logical=True),
                "é¢‘ç‡": f"{psutil.cpu_freq().current:.0f} MHz" if psutil.cpu_freq() else "Unknown"
            },
            "å†…å­˜": {
                "æ€»é‡": f"{psutil.virtual_memory().total / (1024**3):.1f} GB",
                "å¯ç”¨": f"{psutil.virtual_memory().available / (1024**3):.1f} GB"
            },
            "PyTorch": {
                "ç‰ˆæœ¬": torch.__version__,
                "MPSå¯ç”¨": torch.backends.mps.is_available(),
                "MPSæ„å»º": torch.backends.mps.is_built()
            }
        }
        return info
    
    def _get_cpu_model(self):
        """è·å–CPUå‹å·"""
        try:
            if os.system("which sysctl > /dev/null 2>&1") == 0:
                result = subprocess.run(
                    ["sysctl", "-n", "machdep.cpu.brand_string"], 
                    capture_output=True, text=True
                )
                return result.stdout.strip()
        except:
            pass
        return "Unknown"
    
    def print_system_info(self):
        """æ‰“å°ç³»ç»Ÿä¿¡æ¯"""
        info = self.get_system_info()
        print("\nğŸ’» ç³»ç»Ÿä¿¡æ¯")
        print("=" * 50)
        
        for category, details in info.items():
            print(f"{category}:")
            for key, value in details.items():
                print(f"  {key}: {value}")
            print()
    
    def print_training_summary(self, total_epochs):
        """æ‰“å°è®­ç»ƒæ€»ç»“"""
        if not self.start_time:
            return
            
        total_time = time.time() - self.start_time
        
        print("\nğŸ“Š è®­ç»ƒæ€»ç»“")
        print("=" * 50)
        print(f"ğŸ• æ€»è®­ç»ƒæ—¶é—´: {total_time:.2f}s ({total_time/3600:.2f} hours)")
        
        if self.epoch_times:
            avg_epoch_time = sum(self.epoch_times) / len(self.epoch_times)
            print(f"ğŸ“… å¹³å‡Epochæ—¶é—´: {avg_epoch_time:.2f}s")
            print(f"ğŸ”„ å®Œæˆçš„Epochs: {len(self.epoch_times)}")
            
            if len(self.epoch_times) < total_epochs:
                remaining_epochs = total_epochs - len(self.epoch_times)
                eta_total = remaining_epochs * avg_epoch_time
                print(f"â³ é¢„è®¡å‰©ä½™æ—¶é—´: {eta_total/3600:.2f} hours")
        
        if self.batch_times:
            avg_batch_time = sum(self.batch_times) / len(self.batch_times)
            print(f"ğŸ“¦ å¹³å‡Batchæ—¶é—´: {avg_batch_time:.3f}s")
            print(f"ğŸ”„ å¤„ç†çš„Batches: {len(self.batch_times)}")
        
        if self.cpu_usage:
            avg_cpu = sum(self.cpu_usage) / len(self.cpu_usage)
            print(f"ğŸ’» å¹³å‡CPUä½¿ç”¨ç‡: {avg_cpu:.1f}%")
        
        if self.memory_usage:
            avg_memory = sum(self.memory_usage) / len(self.memory_usage)
            print(f"ğŸ’¾ å¹³å‡å†…å­˜ä½¿ç”¨ç‡: {avg_memory:.1f}%")
        
        print(f"ğŸ¯ è®¾å¤‡: {self.device_name.upper()}")
        
        # æ€§èƒ½å»ºè®®
        self._print_performance_recommendations()
    
    def _print_performance_recommendations(self):
        """æ‰“å°æ€§èƒ½å»ºè®®"""
        print("\nğŸ’¡ æ€§èƒ½å»ºè®®")
        print("-" * 30)
        
        if self.batch_times and len(self.batch_times) > 10:
            avg_batch_time = sum(self.batch_times) / len(self.batch_times)
            
            if avg_batch_time > 1.0:
                print("âš ï¸  æ‰¹æ¬¡å¤„ç†æ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®:")
                print("   - å‡å°‘æ‰¹æ¬¡å¤§å°")
                print("   - æ£€æŸ¥æ•°æ®åŠ è½½æ˜¯å¦ä¸ºç“¶é¢ˆ")
                print("   - è€ƒè™‘ä½¿ç”¨æ›´ç®€å•çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•")
            elif avg_batch_time < 0.1:
                print("âœ… æ‰¹æ¬¡å¤„ç†é€Ÿåº¦è‰¯å¥½ï¼Œå¯ä»¥è€ƒè™‘:")
                print("   - å¢åŠ æ‰¹æ¬¡å¤§å°ä»¥æé«˜GPUåˆ©ç”¨ç‡")
                print("   - ä½¿ç”¨æ›´å¤æ‚çš„æ¨¡å‹")
        
        if self.cpu_usage and len(self.cpu_usage) > 10:
            avg_cpu = sum(self.cpu_usage) / len(self.cpu_usage)
            
            if avg_cpu > 80:
                print("âš ï¸  CPUä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®:")
                print("   - å‡å°‘æ•°æ®é¢„å¤„ç†çš„å¤æ‚åº¦")
                print("   - ä½¿ç”¨æ›´å¤šçš„æ•°æ®åŠ è½½å·¥ä½œè¿›ç¨‹")
            elif avg_cpu < 30:
                print("ğŸ’¡ CPUä½¿ç”¨ç‡è¾ƒä½ï¼Œå¯ä»¥è€ƒè™‘:")
                print("   - å¢åŠ æ•°æ®åŠ è½½å·¥ä½œè¿›ç¨‹")
                print("   - è¿›è¡Œæ›´å¤æ‚çš„æ•°æ®å¢å¼º")


# å…¨å±€ç›‘æ§å™¨å®ä¾‹
monitor = None

def get_monitor(device_name="mps"):
    """è·å–ç›‘æ§å™¨å®ä¾‹"""
    global monitor
    if monitor is None:
        monitor = MPSTrainingMonitor(device_name)
    return monitor


if __name__ == "__main__":
    # æµ‹è¯•ç›‘æ§å™¨
    monitor = MPSTrainingMonitor("mps")
    monitor.print_system_info()
