#!/usr/bin/env python3
"""å‘½ä»¤è¡Œæ¨ç†è„šæœ¬ï¼Œç”¨äºä»è®­ç»ƒå¥½çš„DDPMæ¡ä»¶æ¨¡å‹é‡‡æ ·å›¾åƒ"""

import argparse
import json
from pathlib import Path
from typing import List

import torch

from ddpm_conditional import Diffusion
from modules import UNet_conditional
from utils import save_images


def parse_labels(label_arg: str, num_classes: int, device: torch.device) -> torch.Tensor:
    """æ ¹æ®å‘½ä»¤è¡Œå‚æ•°ç”Ÿæˆæ ‡ç­¾å¼ é‡"""
    if label_arg.lower() in {"all", "auto"}:
        return torch.arange(num_classes, device=device)

    try:
        values: List[int] = json.loads(label_arg)
        if isinstance(values, int):
            values = [values]
        if not isinstance(values, list):
            raise ValueError
    except json.JSONDecodeError:
        values = [int(v.strip()) for v in label_arg.split(",") if v.strip()]

    labels = torch.tensor(values, device=device, dtype=torch.long)
    if (labels < 0).any() or (labels >= num_classes).any():
        raise ValueError(f"æ ‡ç­¾å¿…é¡»åœ¨ [0, {num_classes - 1}] èŒƒå›´å†…: {values}")
    return labels


def resolve_device(preferred: str) -> torch.device:
    """æ ¹æ®ä¼˜å…ˆçº§é€‰æ‹©æ¨ç†è®¾å¤‡"""
    if preferred != "auto":
        return torch.device(preferred)

    if torch.cuda.is_available():
        return torch.device("cuda")
    if getattr(torch.backends, "mps", None) and torch.backends.mps.is_available():
        return torch.device("mps")
    return torch.device("cpu")


def main() -> None:
    parser = argparse.ArgumentParser(description="ä½¿ç”¨æ¡ä»¶DDPMæ¨¡å‹è¿›è¡Œå›¾åƒé‡‡æ ·")
    parser.add_argument("--ckpt", default="models/DDPM_conditional/ema_ckpt.pt",
                        help="æ¨¡å‹æƒé‡è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨EMAæƒé‡")
    parser.add_argument("--device", default="auto",
                        help="æ¨ç†è®¾å¤‡ï¼Œé»˜è®¤ä¸ºè‡ªåŠ¨æ£€æµ‹ï¼Œå¯é€‰ cpu/cuda/mps")
    parser.add_argument("--labels", default="all",
                        help="é‡‡æ ·æ ‡ç­¾ï¼Œå¯ç”¨ allã€é€—å·åˆ†éš”çš„æ•´æ•°ï¼Œæˆ–JSONæ•°ç»„")
    parser.add_argument("--cfg-scale", type=float, default=3.0,
                        help="Classifier-Free Guidance ç¼©æ”¾ç³»æ•°")
    parser.add_argument("--image-size", type=int, default=32,
                        help="è®­ç»ƒæ—¶ä½¿ç”¨çš„å›¾åƒå°ºå¯¸")
    parser.add_argument("--num-classes", type=int, default=10,
                        help="æ¡ä»¶ç±»åˆ«æ•°ï¼Œé»˜è®¤ CIFAR-10")
    parser.add_argument("--output", default="results/DDPM_conditional/inference.jpg",
                        help="è¾“å‡ºå›¾ç‰‡è·¯å¾„")

    args = parser.parse_args()

    device = resolve_device(args.device)
    print(f"ğŸ¯ ä½¿ç”¨è®¾å¤‡: {device}")

    model = UNet_conditional(num_classes=args.num_classes, device=device.type, img_size=args.image_size).to(device)

    ckpt_path = Path(args.ckpt)
    if not ckpt_path.exists():
        raise FileNotFoundError(f"æœªæ‰¾åˆ°æ¨¡å‹æƒé‡: {ckpt_path}")

    print(f"ğŸ“‚ åŠ è½½æƒé‡: {ckpt_path}")
    state_dict = torch.load(ckpt_path, map_location=device)
    model.load_state_dict(state_dict)
    model.eval()

    labels = parse_labels(args.labels, args.num_classes, device)
    print(f"ğŸ·ï¸ é‡‡æ ·æ ‡ç­¾: {labels.tolist()}")

    diffusion = Diffusion(img_size=args.image_size, device=device)

    with torch.no_grad():
        samples = diffusion.sample(model, n=len(labels), labels=labels, cfg_scale=args.cfg_scale)

    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    save_images(samples, str(output_path), nrow=len(labels))
    print(f"âœ… é‡‡æ ·å®Œæˆï¼Œå›¾åƒå·²ä¿å­˜è‡³ {output_path}")


if __name__ == "__main__":
    main()
